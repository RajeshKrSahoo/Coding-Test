{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Coding test: Problem statement and Answer-- Python 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## #Q1-- Implement a group_by_owners function that: \n",
    "\n",
    "  <ul>\n",
    "  <li>Accepts a dictionary containing the file owner name for each file name.</li>\n",
    "  <li>Returns a dictionary containing a list of file names for each owner name, in any order.</li>\n",
    "</ul>\n",
    "  \n",
    "  ##### For example, for dictionary {'Input.txt': 'Randy', 'Code.py': 'Stan', 'Output.txt': 'Randy'} the group_by_owners function should return {'Randy': ['Input.txt', 'Output.txt'], 'Stan': ['Code.py']}.\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Randy': ['Input.txt', 'Output.txt'], 'Stan': ['Code.py']}\n"
     ]
    }
   ],
   "source": [
    "inputDict={'Input.txt': 'Randy', 'Code.py': 'Stan', 'Output.txt': 'Randy'}\n",
    "\n",
    "# testInput= {'Input.txt': 'Randy', 'Code.py': 'Stan', 'Output.txt': 'Randy', \"colonel.csv\":\"Rajesh\"}\n",
    "\n",
    "def group_by_owners(inpDict):\n",
    "    owners=set()\n",
    "    ownerDict={}\n",
    "\n",
    "    for fname, ownName in inpDict.items():\n",
    "        owners.add(ownName)\n",
    "\n",
    "    for names in owners:\n",
    "        ownerDict[names]=[]\n",
    "        for fname, ownName in inpDict.items():\n",
    "            if ownName==names:\n",
    "                ownerDict[names].append(fname)\n",
    "    return ownerDict;\n",
    "\n",
    "\n",
    "#Result\n",
    "print(group_by_owners(inputDict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Randy': ['Input.txt', 'Output.txt'], 'Rajesh': ['colonel.csv'], 'Stan': ['Code.py']}\n"
     ]
    }
   ],
   "source": [
    "## result\n",
    "testInput= {'Input.txt': 'Randy', 'Code.py': 'Stan', 'Output.txt': 'Randy', \"colonel.csv\":\"Rajesh\"}\n",
    "print(group_by_owners(testInput))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## #Q2--Write a function that checks if a given word is a palindrome. Character case should be ignored."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word--Meddiff is palaindrome ? : No\n"
     ]
    }
   ],
   "source": [
    "def is_palindromeFn(word):\n",
    "    try:\n",
    "        \n",
    "        #word= input(\"please enter word: \")\n",
    "        word_plndrm=word.lower()\n",
    "        res = str(word_plndrm) == str(word_plndrm)[::-1] \n",
    "        \n",
    "        if res==True:\n",
    "            rslt=\"yes\"\n",
    "        else:\n",
    "            rslt=\"No\"\n",
    "        ##Character case ignored.\n",
    "        print (\"Word--{0} is palaindrome ? : {1}\".format(word,str(rslt)) ) \n",
    "               \n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "\n",
    "        \n",
    "###*****Answer---------**********------------\n",
    "        \n",
    "is_palindromeFn(\"Meddiff\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## #Q3--Write a function to parse a log file & extract details of Errors & Warnings recorded into a separate file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ezsahra\\Documents\\My Received Files\\Config_Log_Output\\log\\*.log\n",
      "['C:\\\\Users\\\\ezsahra\\\\Documents\\\\My Received Files\\\\Config_Log_Output\\\\log\\\\botID1212_auditLog_20190424_170030.log', 'C:\\\\Users\\\\ezsahra\\\\Documents\\\\My Received Files\\\\Config_Log_Output\\\\log\\\\botID1212_auditLog_20190424_170528.log', 'C:\\\\Users\\\\ezsahra\\\\Documents\\\\My Received Files\\\\Config_Log_Output\\\\log\\\\botID1212_debugLog_20190424_170029.log', 'C:\\\\Users\\\\ezsahra\\\\Documents\\\\My Received Files\\\\Config_Log_Output\\\\log\\\\botID1212_debugLog_20190424_170030.log', 'C:\\\\Users\\\\ezsahra\\\\Documents\\\\My Received Files\\\\Config_Log_Output\\\\log\\\\botID1212_debugLog_20190424_170528.log', 'C:\\\\Users\\\\ezsahra\\\\Documents\\\\My Received Files\\\\Config_Log_Output\\\\log\\\\EMA-System-Log-Generated.log']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ezsahra\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:16: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
      "  app.launch_new_instance()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                     time    n          0                1        2     3  \\\n",
      "0     2019-04-24 17:00:41  493  botID1212  botinstance2323  task000  None   \n",
      "1     2019-04-24 17:00:41  611  botID1212  botinstance2323  task000  None   \n",
      "2     2019-04-24 17:00:42  271  botID1212  botinstance2323  task000  None   \n",
      "3     2019-04-24 17:00:42  335  botID1212  botinstance2323  task000  None   \n",
      "4     2019-04-24 17:00:42  442  botID1212  botinstance2323  task000  None   \n",
      "5     2019-04-24 17:00:42  536  botID1212  botinstance2323  task000  None   \n",
      "6     2019-04-24 17:00:42  655  botID1212  botinstance2323  task000  None   \n",
      "7     2019-04-24 17:00:42  748  botID1212  botinstance2323  task000  None   \n",
      "8     2019-04-24 17:00:42  841  botID1212  botinstance2323  task000  None   \n",
      "9     2019-04-24 17:00:42  992  botID1212  botinstance2323  task000  None   \n",
      "10    2019-04-24 17:00:43  113  botID1212  botinstance2323  task000  None   \n",
      "11    2019-04-24 17:00:43  228  botID1212  botinstance2323  task000  None   \n",
      "12    2019-04-24 17:00:43  352  botID1212  botinstance2323  task000  None   \n",
      "13    2019-04-24 17:00:43  447  botID1212  botinstance2323  task000  None   \n",
      "14    2019-04-24 17:00:43  580  botID1212  botinstance2323  task000  None   \n",
      "15    2019-04-24 17:00:43  654  botID1212  botinstance2323  task000  None   \n",
      "16    2019-04-24 17:00:43  699  botID1212  botinstance2323  task000  None   \n",
      "17    2019-04-24 17:00:43  975  botID1212  botinstance2323  task000  None   \n",
      "18    2019-04-24 17:00:44  168  botID1212  botinstance2323  task000  None   \n",
      "19    2019-04-24 17:00:44  454  botID1212  botinstance2323  task000  None   \n",
      "20    2019-04-24 17:00:44  602  botID1212  botinstance2323  task000  None   \n",
      "21    2019-04-24 17:00:44  721  botID1212  botinstance2323  task000  None   \n",
      "22    2019-04-24 17:00:44  894  botID1212  botinstance2323  task000  None   \n",
      "23    2019-04-24 17:00:44  999  botID1212  botinstance2323  task000  None   \n",
      "24    2019-04-24 17:00:45   80  botID1212  botinstance2323  task000  None   \n",
      "25    2019-04-24 17:00:45  148  botID1212  botinstance2323  task000  None   \n",
      "26    2019-04-24 17:00:45  202  botID1212  botinstance2323  task000  None   \n",
      "27    2019-04-24 17:00:45  480  botID1212  botinstance2323  task000  None   \n",
      "28    2019-04-24 17:00:45  561  botID1212  botinstance2323  task000  None   \n",
      "29    2019-04-24 17:00:45  680  botID1212  botinstance2323  task000  None   \n",
      "...                   ...  ...        ...              ...      ...   ...   \n",
      "3325  2019-04-24 17:26:51  702  botID1212  botinstance2323  task000  None   \n",
      "3326  2019-04-24 17:26:51  703  botID1212  botinstance2323  task000  None   \n",
      "3327  2019-04-24 17:26:51  705  botID1212  botinstance2323  task000  None   \n",
      "3328  2019-04-24 17:26:51  706  botID1212  botinstance2323  task000  None   \n",
      "3329  2019-04-24 17:26:51  708  botID1212  botinstance2323  task000  None   \n",
      "3330  2019-04-24 17:26:51  709  botID1212  botinstance2323  task000  None   \n",
      "3331  2019-04-24 17:26:51  711  botID1212  botinstance2323  task000  None   \n",
      "3332  2019-04-24 17:26:51  712  botID1212  botinstance2323  task000  None   \n",
      "3333  2019-04-24 17:26:51  714  botID1212  botinstance2323  task000  None   \n",
      "3334  2019-04-24 17:26:51  715  botID1212  botinstance2323  task000  None   \n",
      "3335  2019-04-24 17:26:51  719  botID1212  botinstance2323  task000  None   \n",
      "3336  2019-04-24 17:26:51  724  botID1212  botinstance2323  task000  None   \n",
      "3337  2019-04-24 17:26:51  728  botID1212  botinstance2323  task000  None   \n",
      "3338  2019-04-24 17:26:51  733  botID1212  botinstance2323  task000  None   \n",
      "3339  2019-04-24 17:26:51  756  botID1212  botinstance2323  task000  None   \n",
      "3340  2019-04-24 17:26:51  761  botID1212  botinstance2323  task000  None   \n",
      "3341  2019-04-24 17:26:51  764  botID1212  botinstance2323  task000  None   \n",
      "3342  2019-04-24 17:26:51  767  botID1212  botinstance2323  task000  None   \n",
      "3343  2019-04-24 17:26:51  770  botID1212  botinstance2323  task000  None   \n",
      "3344  2019-04-24 17:26:51  773  botID1212  botinstance2323  task000  None   \n",
      "3345  2019-04-24 17:26:51  776  botID1212  botinstance2323  task000  None   \n",
      "3346  2019-04-24 17:26:51  778  botID1212  botinstance2323  task000  None   \n",
      "3347  2019-04-24 17:26:51  782  botID1212  botinstance2323  task000  None   \n",
      "3348  2019-04-24 17:26:51  785  botID1212  botinstance2323  task000  None   \n",
      "3349  2019-04-24 17:26:51  788  botID1212  botinstance2323  task000  None   \n",
      "3350  2019-04-24 17:26:51  791  botID1212  botinstance2323  task000  None   \n",
      "3351  2019-04-24 17:26:51  794  botID1212  botinstance2323  task000  None   \n",
      "3352  2019-04-24 17:26:51  797  botID1212  botinstance2323  task000  None   \n",
      "3353  2019-04-24 17:26:51  800  botID1212  botinstance2323  task000  None   \n",
      "3354  2019-04-24 17:26:51  983  botID1212  botinstance2323  task000  None   \n",
      "\n",
      "                                                      4     5     6     7  \n",
      "0     Crozon_Bilan_Cr_1916_V14_Tab_Integration_Chart...  None  None  None  \n",
      "1     Crozon_Bilan_Cr_1916_V14_Tab_Integration_Chart...  None  None  None  \n",
      "2     Crozon_Bilan_Cr_1916_V14_Tab_Integration_Chart...  None  None  None  \n",
      "3     Crozon_Bilan_Cr_1916_V14_Tab_Integration_Chart...  None  None  None  \n",
      "4     Crozon_Bilan_Cr_1916_V14_Tab_Integration_Chart...  None  None  None  \n",
      "5     Crozon_Bilan_Cr_1916_V14_Tab_Integration_Chart...  None  None  None  \n",
      "6     Crozon_Bilan_Cr_1916_V14_Tab_Integration_Chart...  None  None  None  \n",
      "7     Crozon_Bilan_Cr_1916_V14_Tab_Integration_Chart...  None  None  None  \n",
      "8     Crozon_Bilan_Cr_1916_V14_Tab_Integration_Chart...  None  None  None  \n",
      "9     Crozon_Bilan_Cr_1916_V14_Tab_Swap-BA_Chart_01....  None  None  None  \n",
      "10    Crozon_Bilan_Cr_1916_V14_Tab_Swap-BA_Chart_02....  None  None  None  \n",
      "11    Crozon_Bilan_Cr_1916_V14_Tab_Swap-BA_Chart_03....  None  None  None  \n",
      "12    Crozon_Bilan_Cr_1916_V14_Tab_Swap-BA_Chart_04....  None  None  None  \n",
      "13    Crozon_Bilan_Cr_1916_V14_Tab_Swap-BA_Chart_05....  None  None  None  \n",
      "14    Crozon_Bilan_Cr_1916_V14_Tab_Swap-BA_Chart_06....  None  None  None  \n",
      "15    Crozon_Bilan_Cr_1916_V14_Tab_Swap-BA_Chart_07....  None  None  None  \n",
      "16    Crozon_Bilan_Cr_1916_V14_Tab_Swap-BA_Chart_08....  None  None  None  \n",
      "17    Crozon_Bilan_Cr_1916_V14_Tab_Collage_Chart_01....  None  None  None  \n",
      "18    Crozon_Bilan_Cr_1916_V14_Tab_Collage_Chart_02....  None  None  None  \n",
      "19    Crozon_Bilan_Cr_1916_V14_Tab_Collage_Chart_03....  None  None  None  \n",
      "20    Crozon_Bilan_Cr_1916_V14_Tab_Collage_Chart_04....  None  None  None  \n",
      "21    Crozon_Bilan_Cr_1916_V14_Ticket_Chart_01.jpg I...  None  None  None  \n",
      "22    Crozon_Bilan_Cr_1916_V14_Copil1_Chart_01.jpg I...  None  None  None  \n",
      "23    Crozon_Bilan_Cr_1916_V14_Copil1_Chart_02.jpg I...  None  None  None  \n",
      "24    Crozon_Bilan_Cr_1916_V14_Copil1_Chart_03.jpg I...  None  None  None  \n",
      "25    Crozon_Bilan_Cr_1916_V14_Copil1_Chart_04.jpg I...  None  None  None  \n",
      "26    Crozon_Bilan_Cr_1916_V14_Copil1_Chart_05.jpg I...  None  None  None  \n",
      "27    Crozon_Bilan_Cr_1916_V14_Copil1_Chart_06.jpg I...  None  None  None  \n",
      "28    Crozon_Bilan_Cr_1916_V14_Copil1_Chart_07.jpg I...  None  None  None  \n",
      "29    Crozon_Bilan_Cr_1916_V14_Copil2_Chart_01.jpg I...  None  None  None  \n",
      "...                                                 ...   ...   ...   ...  \n",
      "3325           slideNum 72 textToReplace : 0 newText: 0  None  None  None  \n",
      "3326       slideNum 72 textToReplace : wnum newText: 16  None  None  None  \n",
      "3327           slideNum 72 textToReplace : 0 newText: 0  None  None  None  \n",
      "3328       slideNum 72 textToReplace : wnum newText: 16  None  None  None  \n",
      "3329           slideNum 72 textToReplace : 0 newText: 0  None  None  None  \n",
      "3330       slideNum 72 textToReplace : wnum newText: 16  None  None  None  \n",
      "3331           slideNum 72 textToReplace : 0 newText: 0  None  None  None  \n",
      "3332       slideNum 72 textToReplace : wnum newText: 16  None  None  None  \n",
      "3333           slideNum 72 textToReplace : 0 newText: 0  None  None  None  \n",
      "3334       slideNum 72 textToReplace : wnum newText: 16  None  None  None  \n",
      "3335           slideNum 73 textToReplace : 0 newText: 0  None  None  None  \n",
      "3336       slideNum 73 textToReplace : wnum newText: 16  None  None  None  \n",
      "3337       slideNum 73 textToReplace : rnum newText: 35  None  None  None  \n",
      "3338       slideNum 73 textToReplace : wnum newText: 16  None  None  None  \n",
      "3339      slideNum 73 textToReplace : monthR newText: 0  None  None  None  \n",
      "3340       slideNum 73 textToReplace : wnum newText: 16  None  None  None  \n",
      "3341           slideNum 74 textToReplace : 0 newText: 0  None  None  None  \n",
      "3342       slideNum 74 textToReplace : wnum newText: 16  None  None  None  \n",
      "3343        slideNum 74 textToReplace : rnum newText: 0  None  None  None  \n",
      "3344       slideNum 74 textToReplace : wnum newText: 16  None  None  None  \n",
      "3345      slideNum 74 textToReplace : monthR newText: 0  None  None  None  \n",
      "3346       slideNum 74 textToReplace : wnum newText: 16  None  None  None  \n",
      "3347           slideNum 75 textToReplace : 0 newText: 0  None  None  None  \n",
      "3348       slideNum 75 textToReplace : wnum newText: 16  None  None  None  \n",
      "3349           slideNum 75 textToReplace : 0 newText: 0  None  None  None  \n",
      "3350       slideNum 75 textToReplace : wnum newText: 16  None  None  None  \n",
      "3351      slideNum 75 textToReplace : monthR newText: 0  None  None  None  \n",
      "3352       slideNum 75 textToReplace : wnum newText: 16  None  None  None  \n",
      "3353  saving ppt to pathC:\\Users\\epankch\\Ericsson\\Wo...  None  None  None  \n",
      "3354                                          PPT Saved  None  None  None  \n",
      "\n",
      "[3277 rows x 10 columns]\n"
     ]
    }
   ],
   "source": [
    "'''I have used a dummy Log File folder where all the logs are present and used Pandas to get and extract '''\n",
    "\n",
    "import pandas as pd\n",
    "import glob\n",
    "import os\n",
    "import base64\n",
    "\n",
    "def read_logs(folderpath):\n",
    "    try:\n",
    "        print(os.path.join(folderpath, '*.log'))\n",
    "        file_paths = glob.glob(os.path.join(folderpath, '*.log'))\n",
    "        print(file_paths)\n",
    "        # for file_path in file_paths:\n",
    "        df_logs = pd.concat([pd.read_csv(file_path, \n",
    "                                         names=['time', 'n', 'type', ] + list(range(8)),                                      header=None, sep=',\\s*', index_col=None) \\\n",
    "                             for file_path in file_paths], axis=0).reset_index(drop=True)\n",
    "        df_logs.dropna(subset=list(range(1, 7)), how='all', inplace=True)\n",
    "\n",
    "    #     print(df_logs)\n",
    "    \n",
    "        infoLogs= df_logs[df_logs['type'].str.contains(\"INFO\")]\n",
    "\n",
    "        debugLogs= df_logs[df_logs['type'].str.contains(\"DEBUG\")]\n",
    "\n",
    "        errorLogs= df_logs[df_logs['type'].str.contains(\"ERROR\")]\n",
    "\n",
    "        warningLogs= df_logs[df_logs['type'].str.contains(\"WARNING\")]\n",
    "        \n",
    "        '''for getting only details otherthan Level'''\n",
    "        \n",
    "        infoLogs=infoLogs.drop(['type'], axis=1)\n",
    "        warningLogs=warningLogs.drop(['type'], axis=1)\n",
    "        errorLogs=errorLogs.drop(['type'], axis=1)\n",
    "        print(infoLogs)\n",
    "        \n",
    "        \n",
    "        '''separating it to a different file'''\n",
    "        errorLogs.to_csv('errorLog.csv',encoding='utf-8') #all error Logs\n",
    "\n",
    "        warningLogs.to_csv('warningLog.csv',encoding='utf-8') #all warning Logs\n",
    "        \n",
    "        return df_logs\n",
    "    \n",
    "        \n",
    "    \n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "\n",
    "# if __name__ == '__main__':\n",
    "#df_logs = read_logs(r\"C:\\Users\\EZSAHRA\\Desktop\\New folder\\ExpFinal\\log\")\n",
    "\n",
    "#df_logs = read_logs(r\"C:\\Users\\EZSAHRA\\Desktop\\New folder (4)\")\n",
    "\n",
    "df_logs = read_logs(r\"C:\\Users\\ezsahra\\Documents\\My Received Files\\Config_Log_Output\\log\")\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## #Q4--Write a function that provides change directory (cd) function for an abstract file system.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/a/b/c/x\n"
     ]
    }
   ],
   "source": [
    "class Path:\n",
    "    def __init__(self, path):\n",
    "        self.current_path = path\n",
    "\n",
    "    def cd(self, new_path):\n",
    "        try:\n",
    "            i=0;\n",
    "            new_pathList=new_path.split('/')\n",
    "            pathLength=len(new_pathList)\n",
    "            pathList=self.current_path.split('/')\n",
    "            if new_pathList[0]=='':\n",
    "                del pathList[:]\n",
    "                pathList.append('/'+new_pathList[1])\n",
    "                i=i+2\n",
    "            while(i<pathLength):\n",
    "                j=len(pathList)-1\n",
    "                if new_pathList[i]=='..':\n",
    "                    pathList.pop(j)\n",
    "                else:\n",
    "                    pathList.append(new_pathList[i])\n",
    "                i=i+1\n",
    "            self.current_path=\"/\".join(pathList)\n",
    "\n",
    "            pass\n",
    "        \n",
    "        except Excpetion as e:\n",
    "            print(\"Exception\",str(e))\n",
    "            \n",
    "            \n",
    "#*****Answer---------**********------------\n",
    "\n",
    "path = Path('/a/b/c/d')\n",
    "path.cd('../x')\n",
    "print(path.current_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/a/b/c/x\n"
     ]
    }
   ],
   "source": [
    "## Example\n",
    "\n",
    "path = Path('/a/b/c/d')\n",
    "path.cd('../x')\n",
    "print(path.current_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## #Q5--Design & develop a web application to maintain records of students Using Flask and Python\n",
    "\n",
    "#### The single the record shall contain the following information: \n",
    "\n",
    "#### | Name | Roll number | Age | Gender |\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from flask import Flask, request, redirect\n",
    "import os\n",
    "\n",
    "app = Flask(__name__)\n",
    "\n",
    "sInformation=[90]\n",
    "\n",
    "@app.route(\"/studentData\", methods=['GET'])  #Working for GET here an dGET in LoggerToServer\n",
    "def studentData():\n",
    "   \n",
    "    if request.methods==\"GET\":\n",
    "        return sInformation\n",
    "\n",
    "\n",
    "\n",
    "@app.route('/insert', methods=['POST'])\n",
    "def insert():\n",
    "    if request.methods=='POST':\n",
    "        print(\"what data wants to be modified?\")\n",
    "        studentName=request.form['Student Name']\n",
    "        studentRollNumber=request.form['Roll Number']\n",
    "        Branch=request.form['Age']\n",
    "        gender=request.form['Student Gender']\n",
    "        my_list=[studentName,studentRollNumber,Branch,gender]\n",
    "        sInformation.append(my_list)\n",
    "        return sInformation\n",
    "\n",
    "\n",
    "@app.route('/delete', methods=['POST','GET','DELETE'])\n",
    "def delete(dltVal):\n",
    "    sd=[]\n",
    "    if request.methods=='POST':\n",
    "        dltVal=request.form['delete Roll Number: ']\n",
    "\n",
    "        for i,j in enumerate(sInformation):\n",
    "            if dltVal in j:\n",
    "                sInformation.pop(i)\n",
    "        return sInformation\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "@app.route('/search',methods=['POST'])\n",
    "def search(search):\n",
    "    results = []\n",
    "    search_string = search.data['search']\n",
    " \n",
    "    if request.methods==\"POST\":\n",
    "        sd=[]\n",
    "        if search.data['search'] == '':\n",
    "            return sInformation\n",
    "\n",
    "        for i in sInformation:\n",
    "            if search_string in i:\n",
    "                sd.append(i) \n",
    "\n",
    "        if sd==[]:\n",
    "            return \"no record found relatated the information\"\n",
    "\n",
    "        return sd\n",
    "\n",
    "@app.route('/update',methods=['POST','GET'])\n",
    "def update():\n",
    "    if request.methods=='GET':\n",
    "        return sInformation\n",
    "\n",
    "    elif request.methods==\"POST\":\n",
    "        studentName=request.form['Student Name']\n",
    "        studentRollNumber=request.form['Roll Number']\n",
    "        Branch=request.form['Age']\n",
    "        gender=request.form['Student Gender']\n",
    "        my_list=[studentName,studentRollNumber,Branch,gender]\n",
    "\n",
    "        for i,j in enumerate(sInformation):\n",
    "            if studentRollNumber in j:\n",
    "                sInformation.pop(i)\n",
    "                sInformation.insert(i, my_list)\n",
    "\n",
    "        return sInformation\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # app.run(ssl_context='adhoc',debug=True)#ssl_context='adhoc'\n",
    "     app.run(host='0.0.0.0', port=5006, debug=True)\n",
    "    # app.run()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
